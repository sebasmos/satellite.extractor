{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive forward-backward artefact removal algorithm with inter-band data augmentation on satellite imagery\n",
    "To select the best possible image when the satellite does not have data available, combined with cloud removal based on LeastCC, and nearest interpolation for spatial resolution. In order to find the optimal conditions that we expect to improve our results, we plan to augment our dataset with inter-band data and run a variety of different experiments, including the following with different configurations:  Contrast limited adaptive histogram equalization (CLAHE), RGBShift, RandomBrightnessContrast, random cropping, horizontal and vertical flips, gaussian noise, adding hue and saturation to each channel.\n",
    "\n",
    "- **Goal**: Improve overall performance of ML-DL models by \n",
    "\n",
    "        - reducing the data augmentation probability\n",
    "\n",
    "        - Adding gaussian blur \n",
    "        \n",
    "        - In parallel, ML models may implement horizontal/vertical \n",
    "        \n",
    "- Remarks:\n",
    "\n",
    "        - Final images are normalized in range 0-1 and set to float32 to preserve bit-depth from raw data.\n",
    "        - To replace \"bad\" images, the first thing this code does is to copy the full folder containing the images to analyze. This is not necesary, in the future can just read images and store augmented images instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import random\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize\n",
    "import skimage.exposure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "def read_tiff(img_path, resize_ratio=None, resizing = True, normalize=True, printing=True):\n",
    "  img = io.imread(img_path)\n",
    "  img_F =img.copy()\n",
    "  if resize_ratio:\n",
    "    img_F = rescale(img, resize_ratio, anti_aliasing=True)\n",
    "  if resizing:\n",
    "    img_F = resize(img_F, (750,750), anti_aliasing=True)\n",
    "  \n",
    "  path_img = os.path.basename(img_path)\n",
    "  if normalize:\n",
    "    CHANNELS = range(12)\n",
    "    img_F = np.dstack([\n",
    "        skimage.exposure.rescale_intensity(img_F[:,:,c], out_range=(0, 1)) \n",
    "        for c in CHANNELS])\n",
    "  if printing:\n",
    "    print(f\"(origin shape: {path_img}: {img.shape} -> rescale: {str(img_F.shape)}) - Range -> [{img_F.min(), img_F.max()}]\")\n",
    "  return img_F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform tests over a municipality with low-pixel content, such as 230001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path where datasets are located\n",
    "root = \"/home/sebasmos/Desktop/DATASETS/\"\n",
    "\n",
    "# Define name of source dataset\n",
    "source_dataset = \"DATASET_improved_10_cities\"\n",
    "\n",
    "# For testing purpposes on this notebook, select 1 municipality by selecting its name\n",
    "code = 23001\n",
    "\n",
    "# Define target dataset\n",
    "target_dataset = \"DATASET_augmented_v2_gaussian_blur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = os.path.join(root, source_dataset, str(code))\n",
    "aug_root =  os.path.join(root, target_dataset,  str(code))\n",
    "print(f\"root: \", root)\n",
    "print(f\"baseline: \", baseline)\n",
    "print(f\"aug_root: \", aug_root)\n",
    "CLEAN = False\n",
    "if CLEAN:\n",
    "    shutil.rmtree(aug_root)\n",
    "else: \n",
    "    try:\n",
    "        shutil.copytree(baseline, aug_root)\n",
    "    except:\n",
    "        pass\n",
    "images = sorted(glob.glob(os.path.join(baseline)+\"/*.tiff\")) # use sorted to align images temporally back-forwards\n",
    "print(f\"Total # images found on source dataset: \", len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to PART-1, we add new parameter p to parametrize the data augmentation probability of occurance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_satellite_replaced_img_compose_aug(path, resize_ratio=(1, 1, 1)):\n",
    "        \"\"\"\n",
    "        augment_satellite_replaced_img augmentes images given image path on RGB channels only, given probability p\n",
    "        https://albumentations.ai/docs/getting_started/image_augmentation/?query=RandomBrightnessContrast\n",
    "        ::param path: image path\n",
    "\n",
    "        \"\"\"\n",
    "        transform = A.Compose([\n",
    "        A.RandomRotate90(),\n",
    "        #A.Flip(),\n",
    "        #A.Transpose(),\n",
    "        A.OneOf([\n",
    "            A.IAAAdditiveGaussianNoise(),\n",
    "            A.GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.3),\n",
    "            A.GridDistortion(p=.1),\n",
    "            A.IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.2),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=2),\n",
    "            A.IAASharpen(),\n",
    "            A.IAAEmboss(),\n",
    "            A.RandomBrightnessContrast(),            \n",
    "        ], p=0.3),\n",
    "        A.HueSaturationValue(p=0.3),\n",
    "        ])\n",
    "\n",
    "        image_name = path.split(\"/\")[-1][:-5]\n",
    "        img = (255*read_tiff(path, resize_ratio=resize_ratio, resizing = True, normalize=True, printing=True)).astype(\"uint8\")\n",
    "        B =img[:,:,1:4][:,:,0]\n",
    "        G =img[:,:,1:4][:,:,1]\n",
    "        R =img[:,:,1:4][:,:,2]\n",
    "        RGB_img = np.stack([R,G,B]).transpose(2,1,0)\n",
    "        img[:,:,1:4] = transform(image=RGB_img)['image']\n",
    "        return img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results of augmented images here with sample data located in ./data/sample_sentinel2\n",
    "test_local = sorted(glob.glob(os.path.join(\"../data/sample_sentinel2\")+\"/*.tiff\"))\n",
    "\n",
    "for idx, path in enumerate(test_local):\n",
    "\n",
    "    img = augment_satellite_replaced_img(test_local[idx])\n",
    "\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    print(img[:,:,1:4].shape)\n",
    "    print(f\"Range of values for augmented image: Min ({img[:,:,1:4].min()}), Max ({img[:,:,1:4].max()})\")\n",
    "    plt.imshow(img[:,:,1:4])\n",
    "    #if idx==10:\n",
    "    #    break\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving satellite imagery \n",
    "Find the closest image sideways under threshold, apply transformation and replace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_temporal_neighbor(path, images, threshold, resize_ratio = None, resizing = False, normalize = True, printing= False):\n",
    "    \"\"\"\n",
    "    Find the closest temporal neighbor for an image that does not follow np.sum(img)>threshold. The best image is chosen \n",
    "    based on the distance calculated by the counters upward and backward, the closest to the current image will be replaced.\n",
    "\n",
    "    ::param path: current image to be exhanged\n",
    "    ::param images: list of images in current folder containing collection of possible candidates\n",
    "    ::param threshold: minimum threshold to choose image. Integer representing the sum of pixels across width/height \n",
    "\n",
    "    return  image: the best possible replacement for current image.\n",
    "    \"\"\"\n",
    "    upward = 0\n",
    "    backward = 0\n",
    "    current_idx = images.index(path)\n",
    "    t1 = upward + current_idx \n",
    "    t2 = current_idx - backward\n",
    "    neighborUp = \"\"\n",
    "    neighborDown = \"\"\n",
    "    img_up = read_tiff(images[t1], resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "    img_down = read_tiff(images[t2], resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "    # Analize future images and initialize counter\n",
    "    while t1<=len(images) and np.sum(img_up)<threshold:\n",
    "        t1+=1\n",
    "        upward+=1\n",
    "        img_up = read_tiff(images[t1], resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "        neighborUp = images[t1]\n",
    "    # Analize images in the past and initialize counter\n",
    "    while t2>=0 and np.sum(img_down)<threshold:\n",
    "        # if index starts off from 0, bound limits\n",
    "        t2 = int([0 if t2==0 else t2-1][0]) \n",
    "        backward+=1\n",
    "        img_down = read_tiff(images[t2], resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "        neighborDown = images[t2]\n",
    "        # If t2 = 0 and np.sum(image[t2])<0 while np.sum(image[t1])>threshold, \n",
    "        # choose upward by making backward>upward so upward is taken\n",
    "        if t2==0 and np.sum(img_down)<=threshold:\n",
    "            backward=upward+1\n",
    "            t2=t1\n",
    "            break\n",
    "    current = os.path.join(images[current_idx].split(\"/\")[-2:][0], images[current_idx].split(\"/\")[-2:][1])\n",
    "    f_img = os.path.join(images[t1].split(\"/\")[-2:][0], images[t1].split(\"/\")[-2:][1])\n",
    "    b_img = os.path.join(images[t2].split(\"/\")[-2:][0], images[t2].split(\"/\")[-2:][1])\n",
    "    \n",
    "    if upward<backward :\n",
    "        img = read_tiff(images[t1], resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "        assert np.sum(img_up)>=threshold, \"image < threshold\"\n",
    "        print(f\"-->[FORWARD] - image {current} will be replaced with {f_img} - Temporal distance = [Forward = {upward}, backward = {backward}]\")\n",
    "        return augment_satellite_replaced_img(images[t1])\n",
    "    elif upward>backward:\n",
    "        img = read_tiff(images[t2], resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "        assert np.sum(img_down)>=threshold, \"image < threshold\"\n",
    "        print(f\"-->[BACKWARDS] - image {current} will be replaced with {b_img} - Temporal distance = [Forward = {upward}, backward = {backward}]\")\n",
    "        return augment_satellite_replaced_img(images[t2])\n",
    "    elif upward==backward:\n",
    "        r = [t1 if random.choice([\"t1\",\"t2\"]) == \"t1\" else t2][0]\n",
    "        random_img = os.path.join(images[r].split(\"/\")[-2:][0], images[r].split(\"/\")[-2:][1])\n",
    "        img = read_tiff(images[r], resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "        print(f\"-->[EQUIDISTANT] - image {current} will be replaced with {random_img} - Temporal distance = [Forward = {upward} = backward = {backward}]\")\n",
    "        return augment_satellite_replaced_img(images[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "resize_ratio=(1, 1, 1)\n",
    "resize_ratio = None\n",
    "resizing = False\n",
    "normalize = True\n",
    "printing= False\n",
    "count = 0\n",
    "threshold = 5\n",
    "neighbor = \"\"\n",
    "for path in images:\n",
    "    image_name = os.path.join(path.split(\"/\")[-2:][0], path.split(\"/\")[-2:][1])\n",
    "    img = read_tiff(path, resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "    if np.sum(img)<threshold:\n",
    "        # if image content is lower than threshold, replace with the \"best\" image\n",
    "        img = find_closest_temporal_neighbor(path, images, threshold, resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "        assert np.sum(img)>=threshold, \"img is above threshold\"\n",
    "        aug_path = os.path.join(aug_root, path.split(\"/\")[-2:][1])\n",
    "        print(f\"[{count}] Storing augmented image version of {image_name} in: {aug_path}\")\n",
    "        print(img.shape)\n",
    "        \n",
    "        if exists(aug_path):\n",
    "            os.remove(aug_path)\n",
    "            io.imsave(aug_path, img)\n",
    "        else: \n",
    "            io.imsave(aug_path, img)\n",
    "        \n",
    "        if count <=10:    \n",
    "            plt.figure(figsize=(9, 3))\n",
    "            print(img[:,:,1:4].shape)\n",
    "            plt.imshow(img[:,:,1:4])\n",
    "        \n",
    "    else:\n",
    "        print(f\"[{count}] - Image {path} ramains unchanged..\")\n",
    "    count+=1\n",
    "    #if count==5:\n",
    "    #    break\n",
    "images = sorted(glob.glob(os.path.join(aug_root)+\"/*.tiff\")) # use sorted to align images temporally back-forwards\n",
    "print(f\"Total # images: \", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob.glob(os.path.join(aug_root)+\"/*.tiff\")) # use sorted to align images temporally back-forwards\n",
    "for path in images[:3]:\n",
    "    img = read_tiff(path, resize_ratio= resize_ratio, resizing = resizing, normalize=normalize, printing=printing)\n",
    "    plt.figure(figsize=(9, 3))\n",
    "    bands = [9,10,11]\n",
    "    #print(img[:,:,1:4].shape)\n",
    "    plt.imshow(img[:,:,bands])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_path = os.path.join(aug_root, image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad1edc83c8a3ba973d0a5ed89f8d56b42dac8fe366158fcfa7dfa82a998d469f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
